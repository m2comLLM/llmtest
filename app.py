"ChatEXAONE" "Gradio web application for the LlamaIndex RAG system." ""

import config
import gradio as gr
from document_loader import load_documents_from_dir
from embeddings import get_embed_model
from minio_client import get_client, sync_documents
from rag_chain import chat as rag_chat
from rag_chain import get_llm, reset_chat_engine
from vector_store import add_documents, clear_store, get_index


def preload_models():
    """ì•± ì‹œì‘ ì‹œ ëª¨ë“  ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë”©."""
    print("=" * 50)
    print("LlamaIndex RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    print("=" * 50)
    get_embed_model()  # ì„ë² ë”© ëª¨ë¸ ë¡œë”©
    get_index()  # VectorStoreIndex ìƒì„±
    get_llm()  # LLM ì—°ê²°
    print("=" * 50)
    print("ì´ˆê¸°í™” ì™„ë£Œ!")
    print("=" * 50)


def initialize_system():
    """Initialize the RAG system by syncing and indexing documents."""
    status_messages = []

    # Sync documents from MinIO
    try:
        client = get_client()
        downloaded = sync_documents(client)
        status_messages.append(f"MinIOì—ì„œ {len(downloaded)}ê°œ íŒŒì¼ ë™ê¸°í™” ì™„ë£Œ")
    except Exception as e:
        status_messages.append(f"MinIO ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        status_messages.append("ë¡œì»¬ docs/ í´ë”ì˜ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")

    # Load documents (TextNodes)
    nodes = load_documents_from_dir()
    if not nodes:
        return "ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. docs/ í´ë”ì— .md, .csv ë˜ëŠ” .jsonl íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”."

    status_messages.append(f"{len(nodes)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

    # Clear and re-index
    clear_store()
    add_documents(nodes)
    status_messages.append("VectorStoreIndex ì¸ë±ì‹± ì™„ë£Œ")

    return "\n".join(status_messages)


def chat(message: str, history: list) -> str:
    """Process a chat message and return the response."""
    if not message.strip():
        return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

    try:
        response = rag_chat(message)
        return response
    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


def reset_conversation():
    """Reset the conversation history."""
    reset_chat_engine()
    return "ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."


def create_app() -> gr.Blocks:
    """Create the Gradio application."""
    with gr.Blocks(title="ì‚¬ë‚´ RAG ì‹œìŠ¤í…œ (LlamaIndex)") as app:
        gr.Markdown("# ğŸ¢ ì‚¬ë‚´ ë¬¸ì„œ Q&A ì‹œìŠ¤í…œ")
        gr.Markdown("LlamaIndex ê¸°ë°˜ RAG ì‹œìŠ¤í…œ - ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì§€ì›")

        with gr.Row():
            init_btn = gr.Button("ğŸ“š ë¬¸ì„œ ë™ê¸°í™” ë° ì¸ë±ì‹±", variant="primary")
            reset_btn = gr.Button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")

        init_status = gr.Textbox(label="ìƒíƒœ", lines=4, interactive=False)

        init_btn.click(fn=initialize_system, outputs=init_status)
        reset_btn.click(fn=reset_conversation, outputs=init_status)

        gr.Markdown("---")

        chatbot = gr.ChatInterface(
            fn=chat,
            title="ğŸ’¬ ì§ˆë¬¸í•˜ê¸°",
            description="ì—°ë„, ì›”, ì¹´í…Œê³ ë¦¬(ì‹¬í¬ì§€ì—„/ì›Œí¬ìˆ/ìŠ¤ì¿¨ ë“±) í•„í„°ë§ì„ ì§€ì›í•©ë‹ˆë‹¤.",
            examples=[
                "2025ë…„ ì‹¬í¬ì§€ì—„ ëª©ë¡ì„ ì•Œë ¤ì¤˜",
                "2025ë…„ 4ì›” í–‰ì‚¬ ì•Œë ¤ì¤˜",
                "ì–‘ì¬ aTì„¼í„°ì—ì„œ í•˜ëŠ” í–‰ì‚¬ëŠ”?",
            ],
        )

    return app


if __name__ == "__main__":
    preload_models()
    app = create_app()
    app.launch(server_name="0.0.0.0", server_port=7860)
